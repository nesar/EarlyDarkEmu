{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mcmc\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import emcee \n",
    "import time\n",
    "from EarlyDarkEmu.emu import emu_redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def ln_prior(theta, params_list):\n",
    "    pdf_sum = 0\n",
    "    for p, param in zip(theta, params_list):\n",
    "        if not (param[2] < p < param[3]):\n",
    "            return -np.inf\n",
    "        p_mu = 0.5 * (param[3] - param[2]) + param[2]\n",
    "        p_sigma = 1 * (param[3] - p_mu)\n",
    "        pdf_sum += np.log(1.0 / (np.sqrt(2 * np.pi) * p_sigma)) - 0.5 * (p - p_mu) ** 2 / p_sigma ** 2\n",
    "    return pdf_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def ln_like(theta, \n",
    "            redshift,\n",
    "            x_grid, \n",
    "            sepia_model_list, \n",
    "            z_all, \n",
    "            x, \n",
    "            y, \n",
    "            yerr\n",
    "            ):\n",
    "      \n",
    "#     p1, p2, p3, p4, p5 = theta\n",
    "#     new_params = np.array([p1, p2, p3, p4, p5, redshift])[np.newaxis, :]\n",
    "\n",
    "#     new_params = np.array(theta + [redshift])[np.newaxis, :]\n",
    "    new_params = np.append( np.array(theta), [redshift] )[np.newaxis, :]\n",
    "\n",
    "#     print('Theta', len(theta))\n",
    "#     print('New params', new_params.shape)\n",
    "        \n",
    "    model_grid, model_var_grid = emu_redshift(new_params, sepia_model_list, z_all)\n",
    "        \n",
    "    model = np.interp(x, x_grid, model_grid[:, 0])\n",
    "    # model_var = np.interp(x, x_grid, model_var_grid[:, 0, 0])\n",
    "  \n",
    "    # sigma2 = yerr**2  + model_var\n",
    "    sigma2 = yerr**2 \n",
    "\n",
    "    ll = -0.5 * np.sum((y - model)** 2 / sigma2 )\n",
    "    \n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def ln_prob(theta, \n",
    "            redshift,\n",
    "            params_list, \n",
    "            x_grid, \n",
    "            sepia_model_list, \n",
    "            z_all, \n",
    "            x, \n",
    "            y, \n",
    "            yerr\n",
    "            ):\n",
    "    \n",
    "    lp = ln_prior(theta, params_list)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + ln_like(theta, redshift, x_grid, sepia_model_list, z_all, x, y, yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def chain_init(params_list, ndim, nwalkers):\n",
    "    pos0 = [[param[1] * 1.0 for param in params_list] + 1e-3 * np.random.randn(ndim) for _ in range(nwalkers)]\n",
    "    return pos0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def define_sampler(redshift, \n",
    "                   ndim, \n",
    "                   nwalkers, \n",
    "                   params_list, \n",
    "                   x_grid, \n",
    "                   sepia_model_list, \n",
    "                   z_all, \n",
    "                   x, \n",
    "                   y, \n",
    "                   yerr\n",
    "                   ):\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, ln_prob, args=(redshift, params_list, x_grid, sepia_model_list, z_all, x, y, yerr))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def do_mcmc(sampler, \n",
    "            pos, \n",
    "            nrun, \n",
    "            ndim,\n",
    "            if_burn=False\n",
    "            ):\n",
    "    \n",
    "    print('Burn-in phase') if if_burn else print('Sampling phase')\n",
    "\n",
    "    time0 = time.time()\n",
    "    pos, prob, state = sampler.run_mcmc(pos, nrun)\n",
    "\n",
    "    time1 = time.time()\n",
    "    print('time (minutes):', (time1 - time0)/60. )\n",
    "\n",
    "    samples = sampler.chain[:, :, :].reshape((-1, ndim))\n",
    "\n",
    "    if if_burn: \n",
    "        sampler.reset()\n",
    "\n",
    "\n",
    "    if True:\n",
    "\n",
    "        # We'll track how the average autocorrelation time estimate changes\n",
    "        index = 0\n",
    "        autocorr = np.empty(nrun)\n",
    "\n",
    "        # This will be useful to testing convergence\n",
    "        old_tau = np.inf\n",
    "\n",
    "        # Now we'll sample for up to max_n steps\n",
    "        for sample in sampler.sample(pos, iterations=nrun, progress=True):\n",
    "            # Only check convergence every 10 steps\n",
    "            if sampler.iteration % 100:\n",
    "                continue\n",
    "\n",
    "            # Compute the autocorrelation time so far\n",
    "            # Using tol=0 means that we'll always get an estimate even\n",
    "            # if it isn't trustworthy\n",
    "            tau = sampler.get_autocorr_time(tol=0)\n",
    "            autocorr[index] = np.mean(tau)\n",
    "            index += 1\n",
    "\n",
    "            # Check convergence\n",
    "            converged = np.all(tau * 100 < sampler.iteration)\n",
    "            converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "            if converged:\n",
    "                break\n",
    "            old_tau = tau\n",
    "            # print(index)\n",
    "\n",
    "    return pos, prob, state, samples, sampler, autocorr, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def mcmc_results(samples):\n",
    "    results = list(map(lambda v: (v[1], v[2] - v[1], v[1] - v[0]), zip(*np.percentile(samples, [16, 50, 84], axis=0))))\n",
    "    print('mcmc results:', ' '.join(str(result[0]) for result in results))\n",
    "    return tuple(result[0] for result in results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
