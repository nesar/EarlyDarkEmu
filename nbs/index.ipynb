{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyDarkEmu\n",
    "\n",
    "> GP emulator for power spectra in Early Dark Energy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emulator for P(k) for dark matter power spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(not installable yet)\n",
    "```sh\n",
    "pip install EarlyDarkEmu\n",
    "```\n",
    "\n",
    "(Use this development version instead)\n",
    "\n",
    "```sh\n",
    "git clone https://github.com/nesar/EarlyDarkEmu.git\n",
    "cd EarlyDarkEmu/\n",
    "pip install -e '.[dev]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic rundown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EarlyDarkEmu.load import *\n",
    "from EarlyDarkEmu.viz import *\n",
    "from EarlyDarkEmu.pca import *\n",
    "from EarlyDarkEmu.gp import *\n",
    "from EarlyDarkEmu.emu import *\n",
    "from EarlyDarkEmu.mcmc import *\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "if_train_all = False ## Re-train all the models. Time-consuming. \n",
    "if_mcmc_all = False  ## Full MCMC run. Time-consuming. \n",
    "if_savefig = False\n",
    "\n",
    "if_pk_log = True ## P(k) is to be in log10 scaling \n",
    "if_y_scale_plot_log = not if_pk_log\n",
    "if_separate_test_set = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_all = load_params() ## Loading Cosmological Parameters\n",
    "Pk_all, k_all, z_all = load_npy_pk_k_z(pk_log_scale=if_pk_log) # Loading P(k), k and redshift\n",
    "\n",
    "print(p_all.shape, Pk_all.shape, k_all.shape, z_all.shape, PARAM_NAME)\n",
    "print(len(PARAM_NAME))\n",
    "\n",
    "remove_invalid_index = False\n",
    "if remove_invalid_index == True:\n",
    "    remove_sim_indx = [None]\n",
    "    valid_indices = [i for i in  np.arange(Pk_all.shape[0])  if i not in remove_sim_indx]\n",
    "\n",
    "    Pk_all = Pk_all[valid_indices]\n",
    "    p_all = p_all[valid_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few plotting routines\n",
    "\n",
    "#### Experimental design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boost metrics colored by cosmology parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_index = 0\n",
    "z_index = 0\n",
    "\n",
    "plot_lines_with_param_color(p_all[:, color_by_index], \n",
    "                            k_all, \n",
    "                            Pk_all[:, z_index, :], \n",
    "                            'Training data, z=' + str(z_all[z_index]), \n",
    "                            r'$k [h/Mpc]$', \n",
    "                            r'$P(k) [(Mpc/h)^3]$', \n",
    "                            PARAM_NAME[color_by_index],\n",
    "                            y_log_plot_scale=if_y_scale_plot_log);\n",
    "\n",
    "k_sdss, pk_sdss, pk_error_sdss = load_sdss()\n",
    "k_wmap, pk_wmap, pk_error_wmap = load_wmap()\n",
    "\n",
    "plt.errorbar(k_sdss, pk_sdss, yerr=pk_error_sdss, label='SDSS DR7')\n",
    "plt.errorbar(k_wmap, pk_wmap, yerr=pk_error_wmap, label='WMAP + ACT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "color_by_index = 3\n",
    "z_index = 21\n",
    "\n",
    "\n",
    "plot_lines_with_param_color(p_all[:, color_by_index], \n",
    "                            k_all, \n",
    "                            Pk_all[:, z_index, :], \n",
    "                            'Training data, z=' + str(z_all[z_index]), \n",
    "                            r'$k [h/Mpc]$', \n",
    "                            r'$P(k) [(Mpc/h)^3]$', \n",
    "                            PARAM_NAME[color_by_index],\n",
    "                            y_log_plot_scale=if_y_scale_plot_log);\n",
    "\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "z_index = 0\n",
    "\n",
    "f = plot_lines_with_param_color(z_all, \n",
    "                            k_all, \n",
    "                            Pk_all[16, :, :], \n",
    "                            'Training data', \n",
    "                            r'$k [h/Mpc]$', \n",
    "                            r'$P(k) [(Mpc/h)^3]$', \n",
    "                            'redshift',\n",
    "                            y_log_plot_scale=if_y_scale_plot_log);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training involves: PCA, GP fitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not if_separate_test_set: \n",
    "    ## Data prep\n",
    "    z_index = 1\n",
    "    y_vals = Pk_all[:, z_index, :]\n",
    "    # y_ind = np.arange(0, y_vals.shape[1])\n",
    "    y_ind = k_all\n",
    "\n",
    "    # Train-test split\n",
    "    test_indices = [60, 30, 26]\n",
    "    input_params= p_all[test_indices]\n",
    "    target_vals = Pk_all[:, z_index, :][test_indices]\n",
    "\n",
    "\n",
    "    train_indices = [i for i in  np.arange(Pk_all.shape[0]) if i not in test_indices]\n",
    "    p_all_train = p_all[train_indices]\n",
    "    y_vals_train = Pk_all[:, z_index, :][train_indices]\n",
    "    print('Redshift: ' + str(z_all[z_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if if_separate_test_set:\n",
    "\n",
    "    p_all_test = load_params(p_fileIn=LIBRARY_PARAM_FILE_TEST) \n",
    "                              ## Loading Cosmological Parameters\n",
    "    Pk_all_test, k_all_test, z_all_test = load_npy_pk_k_z(Pk_fileIn=LIBRARY_PK_FILE_TEST, \n",
    "                                                          k_fileIn=LIBRARY_K_FILE_TEST, \n",
    "                                                          z_fileIn=LIBRARY_Z_FILE_TEST,\n",
    "                                                          pk_log_scale=if_pk_log) # Loading P(k), k and redshift\n",
    "\n",
    "\n",
    "\n",
    "    ## Data prep\n",
    "    z_index = 1\n",
    "    y_vals = Pk_all[:, z_index, :]\n",
    "    # y_ind = np.arange(0, y_vals.shape[1])\n",
    "    y_ind = k_all\n",
    "\n",
    "    # Train-test split\n",
    "    test_indices = []\n",
    "    input_params= p_all_test\n",
    "    target_vals = Pk_all_test[:, z_index, :]\n",
    "\n",
    "\n",
    "    # train_indices = [i for i in  np.arange(Pk_all.shape[0]) if i not in test_indices]\n",
    "    train_indices = [i for i in  np.arange(Pk_all.shape[0])]\n",
    "    p_all_train = p_all[train_indices]\n",
    "    y_vals_train = Pk_all[:, z_index, :][train_indices]\n",
    "    print('Redshift: ' + str(z_all[z_index]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_a = pd.DataFrame(np.concatenate([p_all, p_all_test], axis=0), columns=PARAM_NAME)\n",
    "colors = ['lightblue']*p_all.shape[0] + ['r']*p_all_test.shape[0]\n",
    "\n",
    "# colors = ['b']*num_sims + ['r']*num_sims_test\n",
    "plot_scatter_matrix(df_train_a, colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepia_data = sepia_data_format(p_all_train, y_vals_train, y_ind)\n",
    "print(sepia_data)\n",
    "model_filename = '../EarlyDarkEmu/model/multivariate_model_z_index' + str(z_index) \n",
    "\n",
    "sepia_model = do_pca(sepia_data, exp_variance=0.98)\n",
    "sepia_model = do_gp_train(sepia_model, model_filename)\n",
    "plot_train_diagnostics(sepia_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepia_model = gp_load(sepia_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-redshift emulation for new cosmological parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_indices_rand = np.random.randint(size=3, low=0, high=input_params.shape[0])\n",
    "test_indices_rand = np.arange(0, input_params.shape[0])\n",
    "pred_mean, pred_quant = emulate(sepia_model, input_params[test_indices_rand])\n",
    "# pred_quant == Emulated (0.05, 0.95) quantile\n",
    "# validation_plot(k_all, target_vals[test_indices_rand], pred_mean, pred_quant, xy_lims=[1e-5, 1e0, 10, 5e4], y_log_scale=if_y_scale_plot_log);\n",
    "validation_plot(k_all, target_vals[test_indices_rand], pred_mean, pred_quant, xy_lims=[1e-5, 1e0, 1, 5], y_log_plot_scale=if_y_scale_plot_log);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis from the emulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = sensitivity_plot(k_all, p_all, sepia_model, emulate, PARAM_NAME, xy_lims = [1e-5, 1e0, 10, 5e4], y_log_plot_scale=if_y_scale_plot_log )\n",
    "f = sensitivity_plot(k_all, p_all, sepia_model, emulate, PARAM_NAME, xy_lims = [1e-5, 1e0, 1, 4.7], y_log_plot_scale=if_y_scale_plot_log )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-redshift emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_train_all:\n",
    "    \n",
    "    do_gp_train_multiple(model_dir='../EarlyDarkEmu/model/', \n",
    "                        p_train_all = p_all[train_indices],\n",
    "                        y_vals_all = Pk_all[train_indices],\n",
    "                        y_ind_all = k_all,\n",
    "                        z_index_range=range(z_all.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepia_model_list = load_model_multiple(model_dir='../EarlyDarkEmu/model/', \n",
    "                                        p_train_all=p_all[train_indices],\n",
    "                                        y_vals_all=Pk_all[train_indices],\n",
    "                                        y_ind_all=k_all,\n",
    "                                        z_index_range=range(z_all.shape[0]), \n",
    "                                        sepia_model_i=sepia_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#### Emulator uncertainty across parameter range\n",
    "\n",
    "input_params0 = input_params[1]\n",
    "z_inputs = 0.05\n",
    "input_params_and_redshift = np.append(input_params0, z_inputs)\n",
    "print(input_params_and_redshift[np.newaxis, :])\n",
    "\n",
    "\n",
    "emulated_with_redshift, emulated_with_redshift_err = emu_redshift(input_params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "\n",
    "\n",
    "plt.figure(433)\n",
    "plt.plot(k_all, emulated_with_redshift[:, 0], label='interp at z=%.4f'%input_params_and_redshift[-1], lw=5, ls='--')\n",
    "plt.plot(k_all, emulate(sepia_model_list[0], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[2])\n",
    "plt.plot(k_all, emulate(sepia_model_list[1], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[3])\n",
    "plt.legend()\n",
    "plt.title('Comparison of redshift-space interpolation')\n",
    "# plt.plot(k_all, emulate(sepia_model_list[0], input_params))\n",
    "# plt.plot(k_all, emulate(sepia_model_list[0], input_params))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emulator confidence across parameter range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter settings\n",
    "steps = 20  # Number of steps in the grid for each parameter\n",
    "param_name_extended = np.append(PARAM_NAME, 'Redshift')\n",
    "red_min = 0\n",
    "red_max = 3\n",
    "red_mean = 1.0\n",
    "\n",
    "param_min = np.append(p_all.min(axis=0), red_min)\n",
    "param_max = np.append(p_all.max(axis=0), red_max)\n",
    "param_mean = np.append(p_all.mean(axis=0), red_mean)\n",
    "\n",
    "# Compute outputs and errors for a range of parameter values\n",
    "def compute_errors(param_grid):\n",
    "    print(param_grid.shape)\n",
    "    errors = np.zeros(shape=(param_grid.shape[0], ))\n",
    "    # errors = np.array([np.mean(emu_redshift(params[np.newaxis, :], sepia_model_list, z_all)[1][:, 0, :]**2) for params in param_grid])\n",
    "    for par_indx in range(errors.shape[0]):\n",
    "\n",
    "        errors[par_indx] = np.mean(emu_redshift(param_grid[par_indx][np.newaxis, :], sepia_model_list, z_all)[1]**2)\n",
    "\n",
    "    return errors.reshape(steps, steps)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "param_indices = [3, 4]  # Indices of parameters to vary\n",
    "fixed_indices = [i for i in range(len(param_name_extended)) if i not in param_indices]\n",
    "fixed_params = {param_name_extended[i]: param_mean[i] for i in fixed_indices}\n",
    "\n",
    "param_grid = generate_param_grid_with_fixed(param_name_extended, param_indices, fixed_params, param_min, param_max, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = compute_errors(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_error_heatmap(errors, [param_name_extended[i] for i in param_indices], [(param_min[param_indices[0]], param_max[param_indices[0]]), (param_min[param_indices[1]], param_max[param_indices[1]])])\n",
    "\n",
    "if if_savefig: \n",
    "    f.savefig('../../../Plots/heatmap_params_4_5.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter inference via MCMC using the emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "ndim = 6\n",
    "nwalkers = 50  # 500\n",
    "nrun_burn = 50  # 300\n",
    "nrun = 400  # 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating mock observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mock_obs = False\n",
    "\n",
    "if create_mock_obs: \n",
    "    target_indx = 0 #0 ,14, 35\n",
    "    z_index = 2\n",
    "    L = 32\n",
    "    fake_obs_data_index_every = 2\n",
    "\n",
    "    redshift = z_all[z_index]\n",
    "    x_target_mcmc = k_all[::fake_obs_data_index_every]\n",
    "    y_target_mcmc = Pk_all[:, z_index, :][target_indx][::fake_obs_data_index_every]\n",
    "\n",
    "    if not if_pk_log: y_target_mcmc = y_target_mcmc*(1 + np.random.normal(0.0, 0.5, size=y_target_mcmc.shape))\n",
    "    if if_pk_log: y_target_mcmc = y_target_mcmc*(1 + 0.02*np.random.normal(0.0, 1, size=y_target_mcmc.shape))\n",
    "\n",
    "    if not if_pk_log: yerr_target_mcmc = np.sqrt( Pk_all[:, z_index, :][target_indx][::fake_obs_data_index_every]*(L**3))/((0.1*L)**3)\n",
    "    if if_pk_log: yerr_target_mcmc = np.sqrt( Pk_all[:, z_index, :][target_indx][::fake_obs_data_index_every]*(L**3))/((0.5*L)**3)\n",
    "\n",
    "    x_grid = k_all\n",
    "    params_calib = p_all[target_indx][:, np.newaxis].T\n",
    "    print('redshift: ', redshift)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not create_mock_obs:\n",
    "    redshift = 0.0\n",
    "\n",
    "    k_sdss, pk_sdss, pk_error_sdss = load_sdss()\n",
    "    k_wmap, pk_wmap, pk_error_wmap = load_wmap()\n",
    "\n",
    "\n",
    "    x_target_mcmc = np.concatenate([k_sdss, k_wmap])\n",
    "    y_target_mcmc = np.concatenate([pk_sdss, pk_wmap])\n",
    "\n",
    "    yerr_target_mcmc = np.concatenate([pk_error_sdss, pk_error_wmap])\n",
    "\n",
    "    params_calib = [[0.1375, 0.7, 0.8, 3.531, 0.1, 2.72]]  ## Best EDE values from 1908.06995\n",
    "    x_grid = k_all\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, a = plt.subplots(1,1, figsize = (8, 5)) \n",
    "input_params_and_redshift = np.append(params_calib, redshift)\n",
    "bk_target, err_target = emu_redshift(input_params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "a.plot(k_all, bk_target[:, 0], label='Emulated at target params', lw=2, ls='--', color='blue')\n",
    "\n",
    "if create_mock_obs:\n",
    "    data_label = 'Target mock observations'\n",
    "else: \n",
    "    data_label = 'Target: SDSS + WMAP + ACT'\n",
    "\n",
    "a.errorbar(x_target_mcmc, y_target_mcmc, yerr_target_mcmc, label=data_label, ls='none', lw=1, color = \"r\")\n",
    "a.scatter(x_target_mcmc, y_target_mcmc, s = 5, marker = \"h\", color = \"k\")\n",
    "\n",
    "\n",
    "a.plot(k_all, Pk_all[:, z_index, :].T, 'k', alpha=0.02)\n",
    "\n",
    "\n",
    "plt.plot(k_all, emulate(sepia_model_list[z_index], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[z_index])\n",
    "plt.plot(k_all, emulate(sepia_model_list[z_index+1], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[z_index + 1])\n",
    "\n",
    "\n",
    "\n",
    "if create_mock_obs: string_print0 = 'Target Params \\n (from sim) \\n\\n' \n",
    "if not create_mock_obs: string_print0 = 'Target params \\n(arXiv:1908.06995) \\n\\n' \n",
    "\n",
    "string_print1 = PARAM_NAME[0] + '= %.4f'%input_params_and_redshift[0] + '\\n'\n",
    "string_print2 = PARAM_NAME[1] + '= %.4f'%input_params_and_redshift[1] + '\\n'\n",
    "string_print3 = PARAM_NAME[2] + '= %.4f'%input_params_and_redshift[2] + '\\n'\n",
    "string_print4 = PARAM_NAME[3] + '= %.4f'%input_params_and_redshift[3] + '\\n'\n",
    "string_print5 = PARAM_NAME[4] + '= %.4f'%input_params_and_redshift[4] + '\\n'\n",
    "string_print6 = PARAM_NAME[5] + '= %.4f'%input_params_and_redshift[5] + '\\n'\n",
    "string_print8 = 'redshift' + '= %.4f'%input_params_and_redshift[6] \n",
    "\n",
    "\n",
    "string_print = string_print0 + string_print1 + string_print2 + string_print3 + string_print4 + string_print5 + string_print6  + string_print8\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='gray', alpha=0.2)\n",
    "plt.text(1.02, 0.1, string_print, transform=a.transAxes, fontsize=12, bbox=props)\n",
    "\n",
    "\n",
    "a.set_xscale('log')\n",
    "# a.set_yscale('log')\n",
    "plt.title('pre-MCMC')\n",
    "a.set_xlabel(r'$k [h/Mpc]$')\n",
    "a.set_ylabel(r'$P(k)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "allMax = np.max(p_all, axis = 0)\n",
    "allMin = np.min(p_all, axis = 0)\n",
    "allMean = np.mean(p_all, axis = 0)\n",
    "\n",
    "param1 = [PARAM_NAME[0], params_calib[0][0], allMin[0], allMax[0]] \n",
    "param2 = [PARAM_NAME[1], params_calib[0][1], allMin[1], allMax[1]]\n",
    "param3 = [PARAM_NAME[2], params_calib[0][2], allMin[2], allMax[2]]\n",
    "param4 = [PARAM_NAME[3], params_calib[0][3], allMin[3], allMax[3]]\n",
    "param5 = [PARAM_NAME[4], params_calib[0][4], allMin[4], allMax[4]]\n",
    "param6 = [PARAM_NAME[5], params_calib[0][5], allMin[5], allMax[5]]\n",
    "\n",
    "\n",
    "# param1 = [PARAM_NAME[0], allMean[0], allMin[0], allMax[0]] \n",
    "# param2 = [PARAM_NAME[1], allMean[1], allMin[1], allMax[1]]\n",
    "# param3 = [PARAM_NAME[2], allMean[2], allMin[2], allMax[2]]\n",
    "# param4 = [PARAM_NAME[3], allMean[3], allMin[3], allMax[3]]\n",
    "# param5 = [PARAM_NAME[4], allMean[4], allMin[4], allMax[4]]\n",
    "# param6 = [PARAM_NAME[5], allMean[5], allMin[5], allMax[5]]\n",
    "# param7 = [PARAM_NAME[6], allMean[6], allMin[6], allMax[6]]\n",
    "\n",
    "params_list = [param1, param2, param3, param4, param5, param6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos0 = chain_init(params_list, ndim, nwalkers)\n",
    "\n",
    "sampler = define_sampler(redshift, ndim, nwalkers, params_list, x_grid, sepia_model_list, z_all, x_target_mcmc, y_target_mcmc, yerr_target_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MCMC run - first burn, then full. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos, prob, state, samples, sampler, autocorr, index = do_mcmc(sampler, pos0, nrun_burn, ndim, if_burn=True)\n",
    "\n",
    "if if_mcmc_all: # Full MCMC-run, will be slow\n",
    "    pos, prob, state, samples, sampler, autocorr, index = do_mcmc(sampler, pos, nrun, ndim, if_burn=False)\n",
    "\n",
    "p_mcmc = mcmc_results(samples)\n",
    "\n",
    "fig = plot_mcmc(samples, params_list, if_truth_know=True)\n",
    "# if if_savefig: \n",
    "#     plt.savefig('../../../Plots/mcmc_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, a = plt.subplots(1,1, figsize = (8, 5)) \n",
    "input_params_and_redshift = np.append(p_mcmc, redshift)\n",
    "bk_mcmc, err_mcmc = emu_redshift(input_params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "a.plot(k_all, bk_mcmc[:, 0], label='Emulated at best MCMC', lw=2, ls='--')\n",
    "a.errorbar(x_target_mcmc, y_target_mcmc, yerr_target_mcmc, label=data_label, ls='none', lw=1, color = \"r\")\n",
    "a.scatter(x_target_mcmc, y_target_mcmc, s = 5, marker = \"h\", color = \"r\", alpha=0.5)\n",
    "\n",
    "a.plot(k_all, Pk_all[:, z_index, :].T, 'k', alpha=0.02)\n",
    "\n",
    "\n",
    "# plt.plot(k_all, emulate(sepia_model_list[z_index], input_params_and_redshift[:-1])[0], label='Z1')\n",
    "# plt.plot(k_all, emulate(sepia_model_list[z_index+1], input_params_and_redshift[:-1])[0], label='Z2')\n",
    "\n",
    "\n",
    "string_print1 = PARAM_NAME[0] + '= %.4f'%params_calib[0][0] + '\\n'\n",
    "string_print2 = PARAM_NAME[1] + '= %.4f'%params_calib[0][1] + '\\n'\n",
    "string_print3 = PARAM_NAME[2] + '= %.4f'%params_calib[0][2] + '\\n'\n",
    "string_print4 = PARAM_NAME[3] + '= %.4f'%params_calib[0][3] + '\\n'\n",
    "string_print5 = PARAM_NAME[4] + '= %.4f'%params_calib[0][4] + '\\n'\n",
    "string_print6 = PARAM_NAME[5] + '= %.4f'%params_calib[0][5] + '\\n'\n",
    "string_print8 = 'redshift' + '= %.4f'%redshift\n",
    "\n",
    "\n",
    "string_print = string_print0 + string_print1 + string_print2 + string_print3 + string_print4 + string_print5 + string_print6  + string_print8\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='gray', alpha=0.2)\n",
    "plt.text(1.02, 0.5, string_print, transform=a.transAxes, fontsize=12, bbox=props)\n",
    "\n",
    "string_print0_mcmc = 'Optimized Params \\n\\n' \n",
    "string_print1_mcmc = PARAM_NAME[0] + '= %.4f'%p_mcmc[0] + '\\n'\n",
    "string_print2_mcmc = PARAM_NAME[1] + '= %.4f'%p_mcmc[1] + '\\n'\n",
    "string_print3_mcmc = PARAM_NAME[2] + '= %.4f'%p_mcmc[2] + '\\n'\n",
    "string_print4_mcmc = PARAM_NAME[3] + '= %.4f'%p_mcmc[3] + '\\n'\n",
    "string_print5_mcmc = PARAM_NAME[4] + '= %.4f'%p_mcmc[4] + '\\n'\n",
    "string_print6_mcmc = PARAM_NAME[5] + '= %.4f'%p_mcmc[5]\n",
    "\n",
    "string_print_mcmc = string_print0_mcmc + string_print1_mcmc + string_print2_mcmc + string_print3_mcmc + string_print4_mcmc + string_print5_mcmc + string_print6_mcmc \n",
    "\n",
    "props = dict(boxstyle='round', facecolor='blue', alpha=0.2)\n",
    "plt.text(1.02, -0.05, string_print_mcmc, transform=a.transAxes, fontsize=12, bbox=props)\n",
    "\n",
    "\n",
    "\n",
    "a.set_xscale('log')\n",
    "# a.set_yscale('log')\n",
    "plt.title('P(k) at MCMC constraints')\n",
    "a.set_xlabel(r'$k [h/Mpc]$')\n",
    "a.set_ylabel(r'$P(k)$')\n",
    "plt.legend()\n",
    "\n",
    "if if_savefig: \n",
    "    plt.savefig('../../../Plots/mcmc_results_Bk.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "\n",
    "if if_mcmc_all:\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    print(tau)\n",
    "\n",
    "    plt.figure(43)\n",
    "    plt.plot(prob)\n",
    "    plt.show()\n",
    "    if if_savefig: \n",
    "        plt.savefig('../../../Plots/prob_plot.png', bbox_inches='tight')\n",
    "\n",
    "    # selected_indices_for_plot = [0, 2, 4]\n",
    "    # fig = plot_mcmc(samples[:, selected_indices_for_plot], [params_list[i] for i in selected_indices_for_plot], if_truth_know=True)\n",
    "\n",
    "    # if if_savefig: \n",
    "    #     plt.savefig('../../../Plots/mcmc_plot_reduced_params.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "\n",
    "def plot_convergence(sampler, params_list, nrun, ndim, nwalkers):\n",
    "    n_params = len(params_list)  # Number of parameters\n",
    "    fig, ax = plt.subplots(n_params, 1, figsize=(20, 2 * n_params), sharex=True)\n",
    "    ax[-1].set_xlabel('steps')\n",
    "\n",
    "    for i, param in enumerate(params_list):\n",
    "        ax[i].plot(np.arange(nrun), sampler.chain[:, :, i].T, lw=0.2, alpha=0.9)\n",
    "        ax[i].text(0.9, 0.9, param[0], horizontalalignment='center', verticalalignment='center', transform=ax[i].transAxes, fontsize=12)\n",
    "\n",
    "    # fig.savefig('plots/convergence_mcmc_ndim{}_nwalk{}_run{}_{}-{}.png'.format(ndim, nwalkers, nrun, summary_stat, design), dpi=100)\n",
    "\n",
    "    return fig\n",
    "\n",
    "if False:\n",
    "    # Example usage\n",
    "    plot_convergence(sampler, params_list, nrun, ndim, nwalkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "if False:\n",
    "\n",
    "    n = 100 * np.arange(1, index + 1)\n",
    "    y_autocarr = autocorr[:index]\n",
    "    plt.plot(n, n / 100.0, \"--k\")\n",
    "    plt.plot(n, y_target_mcmc)\n",
    "    plt.xlim(0, n.max())\n",
    "    plt.ylim(0, y_autocarr.max() + 0.1 * (y_autocarr.max() - y_autocarr.min()))\n",
    "    plt.xlabel(\"number of steps\")\n",
    "    plt.ylabel(r\"mean $\\hat{\\tau}$\");\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "if False:\n",
    "    plt.plot(autocorr)\n",
    "    plt.xscale('log')\n",
    "    # plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher matrix analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fisher Class\n",
    "import numpy as np\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the derivative and p(k) function\n",
    "def power_spectra(params, redshift):\n",
    "    params_and_redshift = np.append(params, redshift)\n",
    "    # pred_mean, pred_err = emulate(sepia_model, params) ## -- use this emu_redshift -- change pred_error\n",
    "    pred_mean, pred_err = emu_redshift(params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "    return pred_mean[:, 0], 10**pred_err[:, 0] ## Check how to scale P(k) and Pk_errors properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FisherMatrix:\n",
    "    def __init__(self, k_values, pk, pk_errors, params):\n",
    "        self.k_values = np.array(k_values)\n",
    "        self.pk = np.array(pk)\n",
    "        self.pk_errors = np.array(pk_errors)\n",
    "        self.params = np.array(params)\n",
    "        # self.redshift = self.redshift\n",
    "        self.n_params = len(params)\n",
    "        self.fmat = np.zeros((self.n_params, self.n_params))\n",
    "\n",
    "    def compute_fmat(self, derivatives):\n",
    "        for i in range(self.n_params):\n",
    "            for j in range(self.n_params):\n",
    "                integrand = derivatives[i] * derivatives[j] / self.pk_errors**2\n",
    "                # self.fmat[i, j] = np.sum(integrand)\n",
    "                self.fmat[i, j] = simps(integrand, self.k_values)\n",
    "        return self.fmat\n",
    "\n",
    "    def uncertainty(self):\n",
    "        if np.linalg.det(self.fmat) == 0:\n",
    "            raise ValueError(\"Fisher is singular.\")\n",
    "        inv_fisher = np.linalg.inv(self.fmat)\n",
    "        return np.sqrt(np.diagonal(inv_fisher))\n",
    "    \n",
    "\n",
    "def deriv(params, redshift, perturb = 1e-5):\n",
    "    n_par = len(params)\n",
    "    pk, _ = power_spectra(params, redshift)\n",
    "\n",
    "    derivative = np.zeros((len(pk), len(pk)))\n",
    "\n",
    "    for i in range(n_par):\n",
    "        params_up  = params.copy()\n",
    "        params_down  = params.copy()\n",
    "\n",
    "        params_up[i] += perturb\n",
    "        params_down[i] -= perturb\n",
    "\n",
    "        # pk_up = power_spectra(kvals, params_up)\n",
    "        # pk_down = power_spectra(kvals, params_down)\n",
    "        pk_up, _ = power_spectra(params_up, redshift)\n",
    "        pk_down, _ = power_spectra(params_down, redshift)\n",
    "\n",
    "        derivative[i] = (pk_up - pk_down)/(2*perturb)\n",
    "        \n",
    "    return derivative, pk_up, pk_down\n",
    "\n",
    "\n",
    "#Using the fmat above we want to calculate hessian ellipses --  need 2x2 matrices\n",
    "def _2x2_matrices(matrix):\n",
    "    n = matrix.shape[0]\n",
    "    pairwise_matrices = []\n",
    "    \n",
    "    # Loop over all pairs (i, j) with i < j\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # Create a 2x2 matrix from the pair\n",
    "            pairwise_matrix = np.array([[matrix[i, i], matrix[i, j]],\n",
    "                                         [matrix[j, i], matrix[j, j]]])\n",
    "            pairwise_matrices.append(pairwise_matrix)\n",
    "    \n",
    "    return pairwise_matrices\n",
    "\n",
    "#Regularizing the matrix before plotting - so it doesn't raise the \"hessian is not neg def\" error\n",
    "def regularize_hessian(H, lambda_reg=1e-5):\n",
    "\n",
    "    H = np.array(H)\n",
    "    \n",
    "    identity_matrix = np.eye(H.shape[0])\n",
    "    H_regularized = H + lambda_reg * identity_matrix\n",
    "    \n",
    "    return H_regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_fid = 0.9\n",
    "param_fid = np.array([0.13844, 0.6991, 0.7997, 3.530, 0.0993, 2.72])\n",
    "\n",
    "\n",
    "pk_fid, pk_error_fid = power_spectra(param_fid, redshift_fid)\n",
    "derivs, pk_up, pk_down = deriv(param_fid, redshift_fid)\n",
    "k_values = np.log10(k_all)\n",
    "fisher = FisherMatrix(k_values, pk_fid, pk_error_fid, param_fid)\n",
    "fmat_fid = fisher.compute_fmat(derivs)\n",
    "fish_all = np.array(_2x2_matrices(-fmat_fid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standalone test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to plot the 2x2 hessian ellipses - Function from Nesar\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone_fisher_test = True\n",
    "\n",
    "if standalone_fisher_test: \n",
    "        param_fiducial = np.array([0.13844, 0.6991, 0.7997, 3.530, 0.0993, 2.72])\n",
    "        p_names = ['$\\\\omega_m$', 'h', '$\\\\sigma_8$', '$\\\\log(z_c)$', '$f_{ede}$', '$\\\\theta_i$']\n",
    "        p_min = np.array([0.12, 0.55, 0.7 , 3.  , 0.  , 0.  ])\n",
    "        p_max = np.array([0.155, 0.85 , 0.9  , 4.   , 0.5  , 3.14 ])\n",
    "\n",
    "        fmat_fid = np.array([[  33602.33436514,  -16812.85135088,  -33306.49447045,\n",
    "         -28651.99102799,    7955.28501939,  -19192.39592227],\n",
    "       [ -16812.85135088,    8471.49395214,   12617.76405109,\n",
    "          12309.1688204 ,    -599.4785199 ,    9966.86094666],\n",
    "       [ -33306.49447045,   12617.76405109,  309579.52928037,\n",
    "         166905.49266398, -238929.54284678,   -5850.67462856],\n",
    "       [ -28651.99102799,   12309.1688204 ,  166905.49266398,\n",
    "          93795.30933078, -122491.4294374 ,    3907.87406654],\n",
    "       [   7955.28501939,    -599.4785199 , -238929.54284678,\n",
    "        -122491.4294374 ,  194898.50173265,   16236.1357093 ],\n",
    "       [ -19192.39592227,    9966.86094666,   -5850.67462856,\n",
    "           3907.87406654,   16236.1357093 ,   13199.13065175]])\n",
    "\n",
    "else: \n",
    "        param_fiducial = p_mcmc\n",
    "        p_names = PARAM_NAME\n",
    "        p_min = allMin\n",
    "        p_max = allMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_contours(hessian, pos, nstd=1., ax=None, **kwargs):\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:, order]\n",
    "\n",
    "    # Ensure Hessian is negative definite for covariance inversion\n",
    "    if np.all(np.linalg.eigvals(-hessian) > 0):\n",
    "        mat = -hessian\n",
    "    else:\n",
    "        raise ValueError(\"The Hessian is not negative definite.\")\n",
    "    cov = np.linalg.pinv(mat)\n",
    "    \n",
    "    # Check for valid covariance values\n",
    "    if not np.all(np.isfinite(cov)):\n",
    "        raise ValueError(\"Covariance matrix contains NaN or Inf.\")\n",
    "\n",
    "    sigma_marg = lambda i: np.sqrt(cov[i, i])\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    if np.any(vals < 0):\n",
    "        raise ValueError(\"Negative eigenvalues found in covariance matrix.\")\n",
    "\n",
    "    theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    width, height = 2 * nstd * np.sqrt(np.abs(vals))\n",
    "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
    "\n",
    "    ax.add_artist(ellip)\n",
    "    sz = max(width, height)\n",
    "    s1 = 1.5 * nstd * sigma_marg(0)\n",
    "    s2 = 1.5 * nstd * sigma_marg(1)\n",
    "\n",
    "    ax.axhline(pos[1], color='blue')\n",
    "    ax.axvline(pos[0], color='blue')\n",
    "\n",
    "    ax.set_xlim(pos[0] - s1, pos[0] + s1)\n",
    "    ax.set_ylim(pos[1] - s2, pos[1] + s2)\n",
    "    plt.draw()\n",
    "    return ellip\n",
    "\n",
    "###################################################################\n",
    "\n",
    "def plot_fisher_grid_aligned(param_names, param_fiducial, fisher_matrix_6x6):\n",
    "    n_params = len(param_names)\n",
    "    fig, axes = plt.subplots(nrows=n_params, ncols=n_params, figsize=(16, 14), sharex='col', sharey='row')\n",
    "    fig.subplots_adjust(top=0.9, right=0.9, left=0.0, bottom=0.0, hspace=0.01, wspace=0.01)\n",
    "\n",
    "    neg_fmat = -fisher_matrix_6x6\n",
    "\n",
    "    for i in range(n_params):\n",
    "        for j in range(n_params):\n",
    "            if i > j:\n",
    "                ax = axes[i, j]\n",
    "                param_duo = np.array([param_fiducial[j], param_fiducial[i]])\n",
    "                fish2x2 = np.array([[neg_fmat[j, j], neg_fmat[j, i]], [neg_fmat[i, j], neg_fmat[i, i]]])\n",
    "                \n",
    "                plot_contours(fish2x2, param_duo, nstd=1., ax=ax, alpha=0.4, fill=True, edgecolor='red', linewidth=2)\n",
    "\n",
    "                if j == 0:\n",
    "                    ax.set_ylabel(param_names[i], fontsize=12)\n",
    "                if i == n_params - 1:\n",
    "                    ax.set_xlabel(param_names[j], fontsize=12)\n",
    "            else:\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fisher_grid_aligned(p_names, param_fiducial, fmat_fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
